<?xml version="1.0" encoding="iso-8859-15"?>

<launch>
  <arg name="camera_topic" default="/zed/zed_node/rgb/image_rect_color"/>
  <arg name="camera_info_topic" default="/zed/zed_node/rgb/camera_info"/>
  <arg name="detected_objects_topic" default="/darknet_ros/bounding_boxes"/>
  <arg name="detected_objects_topic_republished" default="bounding_boxes_republished"/>

  <param name="/yolo" value="true"/>

  <!-- Launch object detector -->
  <!-- Make sure to: 1) configure your launch file -->
  <!--               2) change the topic name for your camera in ros.yaml -->
  <!--               3) change enable_opencv to true and enable_console_output to false to suppress all printing -->
  <!--               4) use relative namespaces in ros.yaml -->
  <include file="$(find darknet_ros)/launch/yolo_v3_zed.launch"/>

  <!-- Launch keypoint detector -->
  <!-- You can choose between keypoint_detector.py if you have a PyTorch built model or keypoint_detector_torch.py if you are converting from Torch -->
  <node name="human_mesh" pkg="object_keypoint_detector" type="human_mesh.py" required="true" output="screen">
    <remap from="detected_objects"    to="$(arg detected_objects_topic)"/>
    <param name="image_topic"         value="$(arg camera_topic)"/>
    <param name="model_path"          value="$(find object_keypoint_detector)/models/model_checkpoint.pt"/>
    <param name="debug"               value="true"/>
  </node>

  <node pkg="rviz" type="rviz" name="rviz" args="-d $(find object_keypoint_detector)/rviz/humans.rviz" />
  
</launch>
